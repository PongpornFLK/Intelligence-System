import streamlit as st
import pandas as pd

st.title("Model development guidelines")
st.subheader("‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏î‡πâ‡∏ß‡∏¢ Neural Network ‡πÅ‡∏ö‡∏ö Multilayer Perceptron (MLP)")

st.link_button("üîó Dataset" , "https://www.kaggle.com/datasets/adilshamim8/education-and-career-success")

# ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á Dataset
csv_path = "./Data_set/education_career_bad_model.csv"
df = pd.read_csv(csv_path)
st.write(df.head(5))



st.markdown("**:blue[1. ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• :red[(] Data Preparation :red[)]]**" )
st.write("- ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ NaN ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å DataFrame , ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'Starting_Salary'", unsafe_allow_html=True) 
st.code("""
df = df.dropna()
df = df[(df["Starting_Salary"] > 5000) & (df["Starting_Salary"] < 200000)]
""")
st.write("- ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ: ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤ Mode", unsafe_allow_html=True) 
st.code("""
for col in df.select_dtypes(include=["float64", "int64"]).columns:
    df[col].fillna(df[col].mean(), inplace=True)

for col in df.select_dtypes(include=["object"]).columns:
    df[col].fillna(df[col].mode()[0], inplace=True)
""")
st.write("- ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Categorical ‡πÄ‡∏õ‡πá‡∏ô One-Hot Encoding ", unsafe_allow_html=True) 
st.code("""
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)
""")
st.write("- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ Features ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ô‡∏ó‡∏î‡∏™‡∏≠‡∏ö ", unsafe_allow_html=True) 
st.code("""
feature_columns = df.drop(columns=["Starting_Salary"]).columns.tolist()
with open(COLUMNS_PATH, "wb") as f:
    pickle.dump(feature_columns, f)
""")
st.write("- ‡πÅ‡∏¢‡∏Å Features (X) ‡πÅ‡∏•‡∏∞ Target (y) ‡πÅ‡∏•‡∏∞ ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ NaN ‡πÉ‡∏ô X ‡πÅ‡∏•‡∏∞ y ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô", unsafe_allow_html=True) 
st.code("""
df_clean = pd.concat([X, y], axis=1).dropna() 
X_clean = df_clean[feature_columns]  
y_clean = df_clean["Starting_Salary"]  
""")
st.write("- ‡∏ó‡∏≥ Feature Scaling: ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ Normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ", unsafe_allow_html=True) 
st.code("""
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_clean)  # ‡πÉ‡∏ä‡πâ X_clean ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß

with open(SCALER_PATH, "wb") as f:
    pickle.dump(scaler, f)
""")


st.markdown("**:blue[2. ‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏Ç‡∏≠‡∏á‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤]**")
st.write("- Multilayer Perceptron (MLP) ‡πÄ‡∏õ‡πá‡∏ô Neural Network ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏±‡πâ‡∏ô‡∏Ç‡∏≠‡∏á Fully Connected Layers ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Activation ‡πÄ‡∏ä‡πà‡∏ô ReLU")
st.write(":green-background[:green[**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á MLP:**]] : <br>-- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏î‡∏µ <br>-- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Activation ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô <br>-- ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ Regularization ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î Overfitting", unsafe_allow_html=True)

st.markdown("**:blue[3. ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• Neural Network]**")
st.write("- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞ Train ‡πÇ‡∏°‡πÄ‡∏î‡∏• MLP Neural Network", unsafe_allow_html=True)
st.code("""
model = keras.Sequential([
    keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),
    keras.layers.BatchNormalization(),
    keras.layers.Dropout(0.3),

    keras.layers.Dense(128, activation='relu'),
    keras.layers.BatchNormalization(),
    keras.layers.Dropout(0.3),

    keras.layers.Dense(64, activation='relu'),
    keras.layers.BatchNormalization(),
    keras.layers.Dropout(0.2),

    keras.layers.Dense(32, activation='relu'),
    keras.layers.BatchNormalization(),

    keras.layers.Dense(1, activation='sigmoid')  # ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
])

model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1)
""")

st.write("- ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Accuracy, MSE, MAE", unsafe_allow_html=True)
st.code("""
y_pred = model.predict(X_test)
y_pred = (y_pred > 0.5).astype(int)  # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô 0 ‡∏´‡∏£‡∏∑‡∏≠ 1

accuracy = np.mean(y_pred == y_test)
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred)

st.write(f"üîπ **Accuracy:** {accuracy:.4f}")
st.write(f"üîπ **Mean Squared Error (MSE):** {mse:.4f}")
st.write(f"üîπ **Mean Absolute Error (MAE):** {mae:.4f}")
st.write(f"üîπ **Root Mean Squared Error (RMSE):** {rmse:.4f}")
st.write(f"üîπ **R¬≤ Score (R2):** {r2:.4f}")
st.write(f"üîπ **Mean Absolute Percentage Error (MAPE):** {mape:.4f}")
""")

st.write("**‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô** Neural Network ‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏Ç‡∏∂‡πâ‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ Netflix ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ Regularization ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î Overfitting ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥", unsafe_allow_html=True)



