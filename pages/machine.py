import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from TrainModel.random_forest import load_and_train_model
from TrainModel.logis_regres import train_logistic_model
from sklearn.metrics import confusion_matrix
from sklearn.linear_model import LogisticRegression

st.title("üß† Machine Learning Model")
with st.spinner("üîÑ Loading and Training Model"):
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model, accuracy, X_test, y_test = load_and_train_model()
    st.success("**Model trained successfully!**")
    st.write("Model Accuracy: ", accuracy)

    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏Å‡∏±‡∏ö‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    y_pred = model.predict(X_test)

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì confusion matrix
    cm = confusion_matrix(y_test, y_pred)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü heatmap ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö confusion matrix
    st.subheader("Random Forest")
    fig, ax = plt.subplots()
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")
    ax.set_title("Confusion Matrix")

    st.pyplot(fig)


# ---------------------------------------------- Logistic Regression ---------------------------------------------- #
# ‡πÉ‡∏ô Streamlit
st.subheader("Logistic Regression")

# ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• Logistic Regression
logistic_model, accuracy_lr, X_test_lr, y_test_lr = train_logistic_model()

st.success("**Logistic Regression Model trained successfully!**")
st.write("Model Accuracy: ", accuracy_lr)

# ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Feature ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡∏≤‡∏¢‡∏∏)
X_feature = X_test_lr[:, 0].reshape(-1, 1)  # ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Age (Feature ‡∏ó‡∏µ‡πà 1)

# **‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡πà‡∏≤ X_range** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏•‡πá‡∏≠‡∏ï‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏™‡πâ‡∏ô S
X_range = np.linspace(X_feature.min(), X_feature.max(), 300).reshape(-1, 1)

# **‡∏™‡∏£‡πâ‡∏≤‡∏á X_range ‡∏ó‡∏µ‡πà‡∏°‡∏µ 4 ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå** (‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏à‡∏≤‡∏Å X_test_lr ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏≠‡∏∑‡πà‡∏ô)
X_range_full = np.tile(X_test_lr.mean(axis=0), (300, 1))  # ‡∏ó‡∏≥‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á X_test_lr
X_range_full[:, 0] = X_range[:, 0]  # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå Age

# **‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô**
y_test_prob = logistic_model.predict_proba(X_test_lr)[:, 1]  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì probability ‡∏Ç‡∏≠‡∏á test data

fig, ax = plt.subplots()
ax.scatter(X_feature, y_test_prob, color='red', label="Actual Data (Predicted Probability)", alpha=0.5)  # ‡∏à‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á
ax.set_xlabel("Feature (Age)")
ax.set_ylabel("Probability")
ax.legend()

st.pyplot(fig)
